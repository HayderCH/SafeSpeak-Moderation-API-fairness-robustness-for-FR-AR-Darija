{
  "dataset_id": "PUB-013",
  "title": "HateCheck Arabic Test Cases",
  "source_url": "https://github.com/mozafari/HateCheck",
  "license": "CC BY 4.0",
  "collection_date": "2021",
  "language_distribution": {
    "ar": 3570
  },
  "label_distribution": {
    "Toxic": 2494,
    "Neutral": 1076
  },
  "slice_notes": "HateCheck test suite for Arabic hate speech detection. Contains systematic test cases covering different functionalities and targets. Used for evaluation purposes.",
  "pii_risk": "Low - Contains synthetic test cases, no real user data",
  "contact": "Evaluation Lead",
  "total_samples": 3570,
  "processing_notes": "Canonicalized with label mapping: hateful->Toxic, non-hateful->Neutral. Marked as test split for evaluation use."
}
